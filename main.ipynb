{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca63955-808a-4399-8fb7-9bda09a7bfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from local files...\n",
      "Data loaded successfully.\n",
      "\n",
      "Starting model training with Softmax and Cross-Entropy...\n",
      "Epoch 1/50, Loss: 0.09826\n",
      "Epoch 11/50, Loss: 0.00094\n",
      "Epoch 21/50, Loss: 0.00035\n",
      "Epoch 31/50, Loss: 0.00021\n",
      "Epoch 41/50, Loss: 0.00015\n",
      "Epoch 50/50, Loss: 0.00012\n",
      "Training complete in 52.26 seconds.\n",
      "\n",
      "Accuracy on first 200 test samples: 95.00%\n",
      "\n",
      "--- Example Predictions (First 10) ---\n",
      "Prediction: 7, True Value: 7\n",
      "Prediction: 2, True Value: 2\n",
      "Prediction: 1, True Value: 1\n",
      "Prediction: 0, True Value: 0\n",
      "Prediction: 4, True Value: 4\n",
      "Prediction: 1, True Value: 1\n",
      "Prediction: 4, True Value: 4\n",
      "Prediction: 9, True Value: 9\n",
      "Prediction: 2, True Value: 5\n",
      "Prediction: 9, True Value: 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct #reads binary info\n",
    "import gzip #reads the file\n",
    "import time #keeps track of time\n",
    "\n",
    "#importing the reusable library\n",
    "from pynnet import Sequential, DenseLayer, ActivationLayer, sigmoid, sigmoid_prime, softmax, categorical_cross_entropy, categorical_cross_entropy_prime\n",
    "#reading the files\n",
    "def read_idx(filename):\n",
    "    \"\"\"Reads an IDX file and returns its content as a numpy array.\"\"\"\n",
    "    try:\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "            shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "            return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "    except gzip.BadGzipFile:\n",
    "        with open(filename, 'rb') as f:\n",
    "            zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "            shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "            return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "def to_categorical(y, num_classes=10):\n",
    "    \"\"\"Converts an integer class vector to a one-hot encoded matrix.\"\"\"\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "#1-Loading the data\n",
    "print(\"Loading data from local files...\")\n",
    "x_train_raw = read_idx('train-images-idx3-ubyte')\n",
    "y_train_raw = read_idx('train-labels-idx1-ubyte')\n",
    "x_test_raw = read_idx('t10k-images-idx3-ubyte')\n",
    "y_test = read_idx('t10k-labels-idx1-ubyte')\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "#2-Preprocessing the data\n",
    "# Normalize pixel values and flatten images\n",
    "x_train = x_train_raw.astype('float32') / 255\n",
    "x_train = x_train.reshape(len(x_train), 28 * 28)\n",
    "# One hot encoding the labels\n",
    "y_train = to_categorical(y_train_raw, 10)\n",
    "\n",
    "# Use a smaller subset for faster training\n",
    "x_train_small = x_train[:1000]\n",
    "y_train_small = y_train[:1000]\n",
    "\n",
    "#3-Model and train\n",
    "model = Sequential()\n",
    "model.add(DenseLayer(28 * 28, 128))\n",
    "model.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "#The final layer uses softmax\n",
    "model.add(DenseLayer(128, 10))\n",
    "model.add(ActivationLayer(softmax, None)) #no prime because the value depends on all neurons\n",
    "\n",
    "#4-Compile and run\n",
    "print(\"\\nStarting model training with Softmax and Cross-Entropy...\")\n",
    "model.compile(loss=categorical_cross_entropy, loss_prime=categorical_cross_entropy_prime, learning_rate=0.1)\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(x_train_small, y_train_small, epochs=50)\n",
    "end_time = time.time()\n",
    "print(f\"Training complete in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "#5-Evaluate model\n",
    "x_test_processed = x_test_raw.astype('float32') / 255\n",
    "x_test_processed = x_test_processed.reshape(len(x_test_processed), 28 * 28)\n",
    "\n",
    "predictions = model.predict(x_test_processed[:200])\n",
    "correct_predictions = sum(1 for i in range(200) if np.argmax(predictions[i]) == y_test[i])\n",
    "accuracy = (correct_predictions / 200) * 100\n",
    "\n",
    "print(f\"\\nAccuracy on first 200 test samples: {accuracy:.2f}%\")\n",
    "print(\"\\n--- Example Predictions (First 10) ---\")\n",
    "for i in range(10):\n",
    "    predicted_digit = np.argmax(predictions[i])\n",
    "    true_digit = y_test[i]\n",
    "    print(f\"Prediction: {predicted_digit}, True Value: {true_digit}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
